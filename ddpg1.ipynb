{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"ddpg1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"P2MHJ5wUG4qA","executionInfo":{"status":"ok","timestamp":1629690302671,"user_tz":-330,"elapsed":931,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Functionality of the ddpg model by default 'Pixel Maximizer' and 'Black Pixel Maximizer' are created\n","Model_Name = \"Pixel Maximizer\""],"id":"P2MHJ5wUG4qA","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"acquired-scout","executionInfo":{"status":"ok","timestamp":1629690302674,"user_tz":-330,"elapsed":7,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Start training from previous checkpoint or not (only default Model_Type can have True)\n","continue_training = False"],"id":"acquired-scout","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9ttkYXDZ7au","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629690305310,"user_tz":-330,"elapsed":7,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}},"outputId":"e496e4e0-f103-40fa-d5c2-d13f108faca7"},"source":["#cell to be used only if running in Google colab, for mounting Drive for I/O\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"V9ttkYXDZ7au","execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3YkCsSgNagJD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629690311768,"user_tz":-330,"elapsed":5608,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}},"outputId":"cb3fbc67-afa4-4237-f418-75b3f4636373"},"source":["#Even Google colab doesn't have these libraries by default so install them\n","!pip install svgwrite\n","!pip install svglib"],"id":"3YkCsSgNagJD","execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: svgwrite in /usr/local/lib/python3.7/dist-packages (1.4.1)\n","Requirement already satisfied: svglib in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from svglib) (1.1.0)\n","Requirement already satisfied: cssselect2>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from svglib) (0.4.1)\n","Requirement already satisfied: reportlab in /usr/local/lib/python3.7/dist-packages (from svglib) (3.6.1)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from svglib) (4.2.6)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from cssselect2>=0.2.0->svglib) (0.5.1)\n","Requirement already satisfied: pillow>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from reportlab->svglib) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xjn-azcraYg_","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1629690311771,"user_tz":-330,"elapsed":20,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}},"outputId":"a3fe680e-4b8d-4c70-a994-9b24ebb7df84"},"source":["#Setup working directory\n","import os\n","working_directory = '/content/drive/MyDrive/vinci-old'\n","os.chdir(working_directory)\n","os.getcwd()"],"id":"xjn-azcraYg_","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/vinci-old'"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"rough-register","executionInfo":{"status":"ok","timestamp":1629690313730,"user_tz":-330,"elapsed":1972,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Created libraries import\n","import sketch_rnn as srnn\n","from HyperParameters import HP\n","import draw"],"id":"rough-register","execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"emerging-conversation","executionInfo":{"status":"ok","timestamp":1629690314718,"user_tz":-330,"elapsed":995,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Installed libraries import\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import tensorflow_probability as tfp\n","import numpy as np\n","import gym\n","from gym import spaces\n","import matplotlib.pyplot as plt\n","import cv2"],"id":"emerging-conversation","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBSEzFKgYDql","executionInfo":{"status":"ok","timestamp":1629690314719,"user_tz":-330,"elapsed":13,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Load the reference image and get the bounds of the image which will set the max stroke length\n","x = np.load(HP.data_location)\n","min_x, max_x, min_y, max_y = draw.get_bounds(x, 0.2)"],"id":"EBSEzFKgYDql","execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"intensive-album","executionInfo":{"status":"ok","timestamp":1629690314720,"user_tz":-330,"elapsed":13,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Training model helper functions\n","@tf.function\n","def sample_gaussian_2d(mu1, mu2, s1, s2, rho):\n","    \"\"\"\n","    This function samples from a 2D-gaussian distribution\n","    \n","    Args:\n","    mu1: mean of the distribution along x-direction\n","    mu2: mean of the distribution along y-direction\n","    s1: std. deviation along x-direction\n","    s2: std. deviation along y-direction\n","    rho: correlation between the two distributiions\n","    \n","    Returns:\n","    a single sample from the distribution\n","    \"\"\"\n","    mean = tf.concat((mu1, mu2), axis=1)\n","    r1 = tf.expand_dims(tf.concat((s1*s1, rho*s1*s2), axis=-1), axis=2)\n","    r2 = tf.expand_dims(tf.concat((rho*s1*s2, s2*s2), axis=-1), axis=2)\n","    cov = tf.concat((r1,r2), axis=2)\n","    dist = tfp.distributions.MultivariateNormalFullCovariance(loc=mean, covariance_matrix=cov)\n","    x = dist.sample()\n","    return x\n","\n","@tf.function\n","def get_mixture_coef(output, temp=HP.temperature):\n","    \"\"\"\n","    This function calculates means, std. deviations, correlations and pen logits from mixture model coefficients\n","    This uses the SketchRNN paper formulae.\n","    \n","    Args:\n","    output: decoderRNN outputs, ie - the GMM coefficients\n","    temp: temperature to control randomness of the output\n","    \n","    Returns:\n","    a list of pi, mean_x, mean_y, sigma_x, sigma_y, correlation, pen logits\n","    \"\"\"\n","    z = output\n","    z_pen_logits = z[:, :, 0:3]\n","    z_pen_logits = z_pen_logits / temp\n","    \n","    z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr = tf.split(z[:, :, 3:], 6, 2)\n","    z_pi = z_pi / temp\n","\n","    z_pi = tf.nn.softmax(z_pi)\n","    z_pen = tf.nn.softmax(z_pen_logits)\n","\n","    z_sigma1 = tf.exp(z_sigma1)\n","    z_sigma1 = z_sigma1 * tf.sqrt(temp)\n","    z_sigma2 = tf.exp(z_sigma2)\n","    z_sigma2 = z_sigma2 * tf.sqrt(temp)\n","    z_corr = tf.tanh(z_corr)\n","    r = [z_pi, z_mu1, z_mu2, z_sigma1, z_sigma2, z_corr, z_pen]\n","    return r\n","\n","def policy(gmms):\n","    \"\"\"\n","    This function takes the decoder outputs and converts it to a 5-element stroke or an \"action\" according to our definition\n","    This function is based on the SketchRNN code.\n","    \n","    Args:\n","    gmms: GMMs outputted by the decoderRNN\n","    \n","    Returns:\n","    a 5-element stroke (action)\n","    \"\"\"\n","    r = get_mixture_coef(gmms)\n","    pi, mux, muy, sigx, sigy, rho, q = r\n","    if pi.shape[0] != 1:\n","        pi = tf.squeeze(pi)\n","        q = tf.squeeze(q)\n","    else:\n","        pi = pi[0]\n","        q = q[0]\n","    pi_idx = tf.argmax(pi, axis=1)\n","    q_idx = tf.argmax(q, axis=1)\n","    if pi_idx.shape[0] != 1:\n","        idx_ref = tf.constant(np.arange(0, HP.batch_size), dtype=tf.int64)\n","    else:\n","        idx_ref = tf.constant(np.arange(0, 1), dtype=tf.int64)\n","    \n","    pi_idx = tf.stack((idx_ref, pi_idx), axis=-1)\n","    mux = tf.expand_dims(tf.gather_nd(mux[:,0], pi_idx), axis=1)\n","    muy = tf.expand_dims(tf.gather_nd(muy[:,0], pi_idx), axis=1)\n","    sigx = tf.expand_dims(tf.gather_nd(sigx[:,0], pi_idx), axis=1)\n","    sigy = tf.expand_dims(tf.gather_nd(sigy[:,0], pi_idx), axis=1)\n","    ro = tf.expand_dims(tf.gather_nd(rho[:,0], pi_idx), axis=1)\n","    \n","    x = sample_gaussian_2d(mux, muy, sigx, sigy, ro)\n","    x = tf.clip_by_value(x, [min_x/8, min_y/8], [max_x/8, max_y/8])\n","    \n","    eos = tf.one_hot(q_idx, 3)\n","    new_elem = tf.concat((x, eos), axis=-1)\n","    return tf.squeeze(new_elem)\n","\n","@tf.function\n","def update_target(target_weights, weights, tau):\n","    \"\"\"\n","    This function updates the target network's weights according to the DDPG method\n","    \n","    Args:\n","    target_weights: weights of the target networks\n","    weights: weights of the actor critic networks (see DDPG paper for more details)\n","    tau: update parameter defined in the DDPG paper\n","    \n","    Returns:\n","    nothing\n","    \"\"\"\n","    for (a, b) in zip(target_weights, weights):\n","        a.assign(b * tau + a * (1 - tau))"],"id":"intensive-album","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwUihL1-Y2WP","executionInfo":{"status":"ok","timestamp":1629690314722,"user_tz":-330,"elapsed":14,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Saving and Checkpointing helper functions\n","def save_models(actor, critic, target_actor, target_critic, save_dir='./model'):\n","    \"\"\"\n","    This function saves all 4 models\n","    \n","    Args:\n","    actor: actor model instance\n","    critic: critic model instance\n","    target_actor: target actor model instance\n","    target_critic: target critic model instance\n","    save_dir: directory to save the models\n","    \n","    Returns:\n","    nothing\n","    \"\"\"\n","    save_dir = os.path.join(save_dir, Model_Name)\n","    try:\n","      os.chdir(save_dir)\n","    except FileNotFoundError:\n","      os.mkdir(save_dir)\n","      os.chdir(save_dir)\n","    actor.save('actor_model')\n","    critic.save('critic_model')\n","    target_actor.save('target_actor_model')\n","    target_critic.save('target_critic_model')\n","    print(\"Saved all models to directory: {}\".format(os.getcwd()))\n","    os.chdir(working_directory)\n","\n","def load_models(save_dir='./model'):\n","    \"\"\"\n","    This function loads all 4 models\n","    \n","    Args:\n","    save_dir: location of the saved models\n","    \n","    Returns:\n","    a list of the 4 models - actor, critic, target_actor, target_critic\n","    \"\"\"\n","    save_dir = os.path.join(save_dir, Model_Name)\n","    try:\n","      os.chdir(save_dir)\n","    except FileNotFoundError:\n","      print(\"Model with specified name does not exist in given directory!\")\n","      os.chdir(working_directory)\n","      return\n","    actor = tf.keras.models.load_model('actor_model')\n","    critic = tf.keras.models.load_model('critic_model')\n","    target_actor = tf.keras.models.load_model('target_actor_model')\n","    target_critic = tf.keras.models.load_model('target_critic_model')\n","    print(\"Loaded all models from directory: {}\".format(os.getcwd()))\n","    os.chdir(working_directory)\n","    return [actor, critic, target_actor, target_critic]\n","\n","def plot_reward(reward_list, save_dir=\"./results\", name=\"final_reward\"):\n","  \"\"\"\n","    This function plots the reward vs episode number and saves it\n","    \n","    Args:\n","    reward_list: list of episodic rewards\n","    save_dir: location to save the plot\n","    name: title of the plot\n","    \n","    Returns:\n","    nothing\n","  \"\"\"\n","  fig = plt.figure()\n","  plt.plot(history)\n","  plt.grid(True, which='both', axis='both')\n","  plt.title(name)\n","  plt.xlabel(\"Episode\")\n","  plt.ylabel(\"Epsiodic Reward\")\n","  plt.show()\n","  plot_dir = os.path.join(save_dir, Model_Name)\n","  try:\n","    os.chdir(plot_dir)\n","  except FileNotFoundError:\n","    os.mkdir(plot_dir)\n","  os.chdir(working_directory)\n","  plot_loc = plot_dir + \"/\" + name + \".png\"\n","  fig.savefig(plot_loc)\n","  print(\"Plot saved to {}\".format(plot_loc))"],"id":"rwUihL1-Y2WP","execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"proper-vancouver","executionInfo":{"status":"ok","timestamp":1629690314723,"user_tz":-330,"elapsed":13,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Reward helper functions\n","def clip_reward(reward, max_reward, min_reward):\n","    \"\"\"\n","    This function clips reward by value\n","    \n","    Args:\n","    reward: calculated reward\n","    max_reward: value of maximum permissible reward\n","    min_reward: value of minimum permissible reward\n","    \n","    Returns:\n","    clipped reward\n","    \"\"\"\n","    if reward >= max_reward:\n","        return max_reward\n","    elif reward <= min_reward:\n","        return min_reward\n","    else:\n","        return reward\n","\n","def count_blacks(img):\n","    \"\"\"\n","    This function calculates the number of black pixels in an image\n","    \n","    Args:\n","    img: image in question\n","    \n","    Returns:\n","    number of black pixels in the image\n","    \"\"\"\n","    _, img_bin = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n","    blacks = np.where(img_bin == 0)\n","    return blacks[0].shape[0]\n","\n","def black_pixel_maximizer_reward(generated_sketch, max_reward, min_reward):\n","    \"\"\"\n","    This function calculates the reward for Black Pixel Maximizer\n","    \n","    Args:\n","    generated_sketch: sketch generated by the actor\n","    max_reward: value of maximum permissible reward\n","    min_reward: value of minimum permissible reward\n","    \n","    Returns:\n","    reward generated by the sketch\n","    \"\"\"\n","    if generated_sketch is None:\n","        return min_reward\n","    else:\n","        blacks = count_blacks(generated_sketch)\n","        rew = ((2*blacks) - generated_sketch.size)/(generated_sketch.size)\n","        return clip_reward(rew, max_reward, min_reward)\n","    \n","def pixel_maximizer_reward(generated_sketch, ref_size, max_reward, min_reward):\n","    \"\"\"\n","    This function calculates the reward for Pixel Maximizer\n","    \n","    Args:\n","    generated_sketch: sketch generated by the actor\n","    ref_size: number of pixels in the reference image\n","    max_reward: value of maximum permissible reward\n","    min_reward: value of minimum permissible reward\n","    \n","    Returns:\n","    reward generated by the sketch\n","    \"\"\"\n","    if generated_sketch is None:\n","        return min_reward\n","    else:\n","        rew = (generated_sketch.size - ref_size)/ref_size\n","        return clip_reward(rew, max_reward, min_reward)"],"id":"proper-vancouver","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"dried-conflict","executionInfo":{"status":"ok","timestamp":1629690315783,"user_tz":-330,"elapsed":5,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#RL environment setup according to the discussion in the final report\n","class SketchEnvironment(gym.Env):\n","    metadata = {'render.mode': ['human']}\n","    \n","    def __init__(self, test_img, encoder_model):\n","        \"\"\"\n","        Gym Environment Initializer\n","    \n","        Args:\n","        test_img: strokes of the refence image\n","        encoder_model: encoderRNN based on the sketchRNN\n","    \n","        Returns:\n","        Gym Environment\n","        \"\"\"\n","        super(SketchEnvironment, self).__init__()\n","        self.example = test_img\n","        self.action_space = spaces.Box(low=np.array([min_x/8,min_y/8,0,0,0]),\n","                                       high=np.array([max_x/8,max_y/8,1,1,1]),\n","                                       dtype=np.float64)\n","        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,\n","                                            shape=(1,HP.latent_dim),\n","                                            dtype=np.float64)\n","        self.encoder = encoder_model\n","        img = cv2.imread('./source.png', flags=cv2.IMREAD_GRAYSCALE)\n","        self.example_size = img.size\n","        self.time_step = 0\n","\n","        self.z = None\n","\n","        self.strokes = []\n","\n","        self.max_reward = 1\n","        self.min_reward = -1\n","        \n","    def reset(self):\n","        \"\"\"\n","        This function resets the environment to the initial state\n","        \n","        Args:\n","        None\n","        \n","        Returns:\n","        Initial states for the actor and critic\n","        \"\"\"\n","        h_0, c_0, z = self.encoder(self.example, training=False)\n","        self.time_step = 0\n","        self.strokes = []\n","        self.z = z\n","        a0 = np.array([0,0,1,0,0])\n","        a0 = np.expand_dims(a0, axis=0)\n","        state = np.concatenate((a0, z), axis=1)\n","        return h_0, c_0, state\n","    \n","    def step(self, action):\n","        \"\"\"\n","        This function performs a step in the environment\n","        \n","        Args:\n","        action: the action taken by the actor\n","        \n","        Returns:\n","        next state, reward for current action, bool whether or not the current episode is done, info dictionary\n","        \"\"\"\n","        self.strokes.append(action)\n","        done = action[4]\n","        action = np.expand_dims(action, axis=0)\n","        reward = self._get_reward()\n","        self.time_step += 1\n","        state = np.concatenate((action, self.z), axis=1)\n","        return state, reward, done, {}\n","    \n","    def _get_reward(self):\n","        \"\"\"\n","        This function calculates the reward for the current action\n","        \n","        Args:\n","        None\n","        \n","        Returns:\n","        reward for current action\n","        \n","        Raises:\n","        UndefinedRewardError - denoting that the desired model reward is not among the default ones.\n","        \"\"\"\n","        draw.draw_strokes(np.array(self.strokes), svg_filename='./destination.svg', save_to_file=True)\n","        gen_sketch = cv2.imread('./destination.png', flags=cv2.IMREAD_GRAYSCALE)\n","        if Model_Name == 'Black Pixel Maximizer':\n","            return black_pixel_maximizer_reward(gen_sketch, self.max_reward, self.min_reward)\n","        elif Model_Name == 'Pixel Maximizer':\n","            return pixel_maximizer_reward(gen_sketch, self.example_size, self.max_reward, self.min_reward)\n","        else:\n","            raise UndefinedRewardError('Please define the desired reward function')\n","    \n","    def render(self, mode='human', close=False):\n","        filename = './results' + '/episode_' + str(self.time_step) + '.svg'\n","        draw.draw_strokes(np.array(self.strokes), svg_filename=filename, show=True)"],"id":"dried-conflict","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"innocent-jefferson","executionInfo":{"status":"ok","timestamp":1629690317647,"user_tz":-330,"elapsed":10,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Action Noise definition according to the DDPG paper (Ornstein-Uhlenbeck process)\n","class OUActionNoise:\n","    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n","        \"\"\"\n","        Noise process initializer\n","        \n","        Args:\n","        mean: mean of the process\n","        std_deviation: standard deviation of the noise\n","        dt: time interval between two process samples\n","        x_initial: initial state\n","        \n","        Returns:\n","        Action Noise object\n","        \"\"\"\n","        self.theta = theta\n","        self.mean = mean\n","        self.std_dev = std_deviation\n","        self.dt = dt\n","        self.x_initial = x_initial\n","        self.reset()\n","\n","    def __call__(self):\n","        \"\"\"\n","        This defines the call behaviour of the noise object. \n","        Behaviour taken from https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process\n","        \n","        Args:\n","        None\n","        \n","        Returns:\n","        A sample from the noise process\n","        \"\"\"\n","        x = (\n","            self.x_prev\n","            + self.theta * (self.mean - self.x_prev) * self.dt\n","            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n","        )\n","        \n","        self.x_prev = x\n","        return x\n","\n","    def reset(self):\n","        \"\"\"\n","        Function to reset the noise to initial state\n","        \n","        Args:\n","        None\n","        \n","        Returns:\n","        nothing\n","        \"\"\"\n","        if self.x_initial is not None:\n","            self.x_prev = self.x_initial\n","        else:\n","            self.x_prev = np.zeros_like(self.mean)"],"id":"innocent-jefferson","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"finite-school","executionInfo":{"status":"ok","timestamp":1629690317649,"user_tz":-330,"elapsed":9,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Replay Buffer for experience based training according to the DDPG paper\n","class Buffer:\n","    def __init__(self, buffer_capacity=100000, batch_size=HP.batch_size):\n","        \"\"\"\n","        Replay Buffer Initializer\n","        \n","        Args:\n","        buffer_capacity: size of the buffer\n","        batch_size: batch_size for training\n","        \n","        Returns:\n","        Buffer class object\n","        \"\"\"\n","        self.buffer_capacity = buffer_capacity\n","        self.batch_size = batch_size\n","        self.buffer_counter = 0\n","        \n","        num_states = HP.latent_dim + 2*HP.dec_hidden_size + HP.input_dimension\n","        num_actions = HP.input_dimension\n","        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n","        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n","        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n","        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n","\n","    def record(self, obs_tuple):\n","        \"\"\"\n","        This performs recording of the (s, a, r, s') tuple according to DDPG paper\n","        \n","        Args:\n","        obs_tuple: the tuple (state, action, reward, next_state)\n","        \n","        Returns:\n","        Nothing\n","        \"\"\"\n","        index = self.buffer_counter % self.buffer_capacity\n","\n","        self.state_buffer[index] = np.concatenate(obs_tuple[0], axis=1)\n","        self.action_buffer[index] = obs_tuple[1]\n","        self.reward_buffer[index] = obs_tuple[2]\n","        self.next_state_buffer[index] = np.concatenate(obs_tuple[3], axis=1)\n","\n","        self.buffer_counter += 1\n","    \n","    @tf.function\n","    def update(\n","        self, state_batch, action_batch, reward_batch,\n","        next_state_batch,\n","    ):\n","        \"\"\"\n","        This is the main training step. Performs a step of training according to the DDPG algorithm.\n","        \n","        Args:\n","        state_batch: batch of current states\n","        action_batch: batch of actions taken in the state\n","        reward_batch: batch of rewards received for above states and actions\n","        next_state_batch: batch of states we went into after performing the actions\n","        \n","        Returns:\n","        Nothing\n","        \"\"\"\n","        h, c, s = tf.split(state_batch, [HP.dec_hidden_size, HP.dec_hidden_size, 5+HP.latent_dim], axis=-1)\n","        h_new, c_new, s_new = tf.split(next_state_batch, [HP.dec_hidden_size, HP.dec_hidden_size, HP.latent_dim+5], axis=-1)\n","        with tf.GradientTape() as tape1:\n","            actor_input = tf.expand_dims(s_new, axis=1)\n","            target_actions, _, _ = target_actor([actor_input, h_new, c_new], training=True)\n","            target_actions = tf.expand_dims(policy(target_actions), axis=1)\n","            critic_input = tf.concat((tf.cast(target_actions, tf.float64), actor_input), axis=-1)\n","            y = reward_batch + HP.gamma * target_critic(\n","                [critic_input, h_new, c_new], training=True)\n","            actions = tf.expand_dims(action_batch, axis=1)\n","            critic_input = tf.concat((tf.cast(actions, tf.float64), tf.expand_dims(s, axis=1)), axis=-1)\n","            critic_value = critic([critic_input, h, c], training=True)\n","            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n","\n","        critic_grad = tape1.gradient(critic_loss, critic.trainable_variables)\n","        critic_optimizer.apply_gradients(\n","            zip(critic_grad, critic.trainable_variables)\n","        )\n","\n","        with tf.GradientTape() as tape2:\n","            actor_input = tf.expand_dims(s, axis=1)\n","            actions, _, _ = actor([actor_input, h, c], training=True)\n","            action = tf.expand_dims(policy(actions), axis=1)\n","            critic_input = tf.concat((tf.cast(action, tf.float64), tf.expand_dims(s, axis=1)), axis=-1)\n","            critic_value = critic([critic_input, h, c], training=True)\n","            actor_loss = -tf.math.reduce_mean(critic_value)\n","\n","        actor_grad = tape2.gradient(actor_loss, actor.trainable_variables)\n","        actor_optimizer.apply_gradients(\n","            zip(actor_grad, actor.trainable_variables)\n","        )\n","        \n","    def learn(self):\n","        \"\"\"\n","        Samples a batch from the Replay Buffer and performs a training step\n","        \n","        Args:\n","        None\n","        \n","        Returns:\n","        Nothing\n","        \"\"\"\n","        record_range = min(self.buffer_counter, self.buffer_capacity)\n","        batch_indices = np.random.choice(record_range, self.batch_size)\n","        \n","        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n","        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n","        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n","        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n","        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n","        \n","        self.update(state_batch, action_batch, reward_batch, next_state_batch)"],"id":"finite-school","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-1gygnhJLIx","executionInfo":{"status":"ok","timestamp":1629690318581,"user_tz":-330,"elapsed":3,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#setup the required environment, models and other modules\n","def get_setup(continue_train=False):\n","  \"\"\"\n","    This function loads the environment, actor, critic, target actor, target critic, replay buffer, noise and encoderRNN\n","    \n","    Args:\n","    continue_train: bool denoting whether to use pretrained model or initialize new ones\n","    \n","    Returns:\n","    A list of the above mentioned instances\n","  \"\"\"\n","  if not continue_train:\n","    x = np.load(HP.data_location)\n","    img = np.expand_dims(x, axis = 0)\n","  else:\n","    img = np.load(\"./model/\" + Model_Name + \"/final_state.npy\")\n","\n","  encoder = srnn.get_encoderRNN()\n","\n","  env = SketchEnvironment(img, encoder)\n","  buffer = Buffer(HP.buffer_size, HP.batch_size)\n","\n","  ou_noise = OUActionNoise(mean=np.zeros((1, 1, (6*HP.M + 3))),\n","                         std_deviation=float(HP.noise_stddev) * np.ones((1, 1, (6*HP.M + 3))))\n","  \n","  if continue_train:\n","    actor, critic, target_actor, target_critic = load_models()\n","\n","  else:\n","    actor = srnn.get_decoderRNN(critic=False)\n","    critic = srnn.get_decoderRNN(critic=True)\n","\n","    target_actor = srnn.get_decoderRNN(critic=False)\n","    target_critic = srnn.get_decoderRNN(critic=True)\n","\n","    target_actor.set_weights(actor.get_weights())\n","    target_critic.set_weights(critic.get_weights())\n","\n","  return [encoder, env, buffer, ou_noise, actor, critic, target_actor, target_critic]"],"id":"r-1gygnhJLIx","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"varying-screw","executionInfo":{"status":"ok","timestamp":1629690322129,"user_tz":-330,"elapsed":5,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Main training loop\n","def train():\n","  \"\"\"\n","    The main training loop which trains and saves the models\n","    \n","    Args:\n","    None\n","    \n","    Returns:\n","    the list of episodic rewards as a function of the number of episodes\n","  \"\"\"\n","  ep_reward_list = []\n","  early_stopping_counter = 0\n","  for ep in range(HP.total_episodes):\n","    h_0, c_0, state = env.reset()\n","    prev_s = np.expand_dims(state, axis=0)\n","    prev_state = [h_0, c_0, state]\n","    episodic_reward = 0\n","    for i in range(HP.max_seq_length):\n","        dec_out, h_new, c_new = actor([prev_s, h_0, c_0])\n","        noise = ou_noise()\n","        dec_out = dec_out + noise\n","        action = policy(dec_out)\n","        \n","        state, reward, done, info = env.step(action)\n","\n","        state_ex = np.expand_dims(state, axis=0)\n","        state = [h_new, c_new, state]\n","\n","        episodic_reward += reward\n","        \n","        buffer.record((prev_state, action, reward, state))\n","        \n","        if done:\n","            break\n","            \n","        prev_state = state\n","        prev_s = state_ex\n","        h_0 = h_new\n","        c_0 = c_new\n","    \n","    buffer.learn()\n","    update_target(target_actor.variables, actor.variables, HP.tau)\n","    update_target(target_critic.variables, critic.variables, HP.tau)\n","    ep_reward_list.append(episodic_reward / (i+1))\n","    while i < (HP.max_seq_length - 1):\n","        dummy_action = np.array([0, 0, 1, 0, 0])\n","        env.strokes.append(dummy_action)\n","        i += 1\n","    env.example = np.expand_dims(np.array(env.strokes), axis=0)\n","\n","    print(\"Episode: {}, reward = {}\".format(ep, ep_reward_list[-1]))\n","    if ep%10 == 0:\n","       env.render(ep)\n","  \n","  np.save(\"./model/\" + Model_Name + \"/final_state.npy\", env.example)\n","  save_models(actor, critic, target_actor, target_critic)\n","  return ep_reward_list"],"id":"varying-screw","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"bV6QK2ERxgCi","executionInfo":{"status":"ok","timestamp":1629690322637,"user_tz":-330,"elapsed":5,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Main evaluation loop\n","def get_ground_truth():\n","    \"\"\"\n","    This function is used to test the model. It uses the target actor and creates a single sketch.\n","    \n","    Args:\n","    None\n","    \n","    Returns:\n","    numpy array of strokes to generate the sketch\n","    \"\"\"\n","    strokes = []\n","    h_0, c_0, state = env.reset()\n","    prev_s = np.expand_dims(state, axis=0)\n","    for i in range(HP.max_seq_length):\n","        dec_out, h_new, c_new = target_actor([prev_s, h_0, c_0], training=False)\n","        action = policy(dec_out)\n","        strokes.append(action)\n","        state, _, _, _ = env.step(action)\n","        prev_s = np.expand_dims(state, axis=0)\n","        h_0 = h_new\n","        c_0 = c_new\n","\n","    strokes = np.array(strokes)\n","    return strokes"],"id":"bV6QK2ERxgCi","execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"prerequisite-situation","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629690337723,"user_tz":-330,"elapsed":13964,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}},"outputId":"35ee3134-ae19-46dd-c3cb-f4c18678843b"},"source":["#Call all the above functions and setup the ddpg-sketchRNN environment\n","encoder, env, buffer, ou_noise, actor, critic, target_actor, target_critic = get_setup(continue_training)\n","\n","#Set the actor and critic optimizers\n","critic_optimizer = tf.keras.optimizers.Adam(HP.critic_lr)\n","actor_optimizer = tf.keras.optimizers.Adam(HP.actor_lr)"],"id":"prerequisite-situation","execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","Loaded all models from directory: /content/drive/MyDrive/vinci-old/model/Pixel Maximizer\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S9KPfsT_FyHW","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1629690708299,"user_tz":-330,"elapsed":319414,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}},"outputId":"6b5096b8-4067-43a8-d7c6-7de7267adb03"},"source":["#Train the models\n","history = train()"],"id":"S9KPfsT_FyHW","execution_count":23,"outputs":[{"output_type":"stream","text":["Episode: 0, reward = 0.887785864978903\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.SVG object>"],"image/svg+xml":"<svg baseProfile=\"full\" height=\"752.3167207837105\" version=\"1.1\" width=\"878.9235802832991\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"752.3167207837105\" width=\"878.9235802832991\" x=\"0\" y=\"0\"/><path d=\"M25,25 m1.6768467426300049,4.523546099662781 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l1.8912103772163391,5.177204608917236 10.214484930038452,5.177204608917236 l8.776213526725769,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l2.1673762798309326,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 8.188466429710388,5.177204608917236 l6.282831430435181,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 6.41179084777832,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 8.653576970100403,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l8.00450086593628,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 2.3595792055130005,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l4.79170024394989,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l0.6336391717195511,-3.777959942817688 9.055188298225403,-3.401135206222534 l9.174179434776306,-3.777959942817688 0.0,5.177204608917236 l0.0,-3.777959942817688 9.704686999320984,-3.5606423020362854 l10.214484930038452,1.6345959901809692 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l7.25757360458374,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 8.617733716964722,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l1.7006075382232666,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l1.8810999393463135,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,5.177204608917236 10.015912055969238,5.177204608917236 l0.0,5.177204608917236 4.432361125946045,5.177204608917236 l0.0,5.177204608917236 0.0,5.177204608917236 l0.0,-3.777959942817688 0.0,-3.777959942817688 l3.3259496092796326,-3.777959942817688 6.236408948898315,-3.777959942817688 l6.676589250564575,-3.777959942817688 5.531024932861328,-3.777959942817688 l4.269543290138245,-3.777959942817688 3.2265329360961914,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l1.0097838938236237,-3.777959942817688 2.125704288482666,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 1.614910364151001,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l1.3199250400066376,-3.777959942817688 2.07706555724144,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 1.1124573647975922,-3.777959942817688 l1.6458775103092194,-3.777959942817688 0.0,-3.777959942817688 l0.5299882218241692,-3.777959942817688 1.295684576034546,-3.777959942817688 l0.0,-3.777959942817688 0.24521518498659134,-3.777959942817688 l0.3521931543946266,-3.777959942817688 0.4325796663761139,-3.777959942817688 l0.18604587763547897,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.014472948387265205,-3.777959942817688 0.0770324096083641,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 0.0,-3.777959942817688 l0.0,-3.777959942817688 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"},"metadata":{}},{"output_type":"stream","text":["Episode: 1, reward = 0.6951191983122362\n","Episode: 2, reward = 0.8766990154711674\n","Episode: 3, reward = 0.8393558368495078\n","Episode: 4, reward = 0.8999722222222222\n","Episode: 5, reward = 0.8826849507735584\n","Episode: 6, reward = 0.882493670886076\n","Episode: 7, reward = 0.7743688466947961\n","Episode: 8, reward = 0.6953635724331926\n","Episode: 9, reward = 0.7563340365682137\n","Episode: 10, reward = 0.8600098452883264\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.SVG object>"],"image/svg+xml":"<svg baseProfile=\"full\" height=\"383.3283694833517\" version=\"1.1\" width=\"1347.2395861148834\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"383.3283694833517\" width=\"1347.2395861148834\" x=\"0\" y=\"0\"/><path d=\"M25,28.777959942817688 m0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-1.4600922167301178 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-0.9675701707601547 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-1.2221874296665192 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-1.5106259286403656 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-1.5317319333553314 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-1.324894279241562 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-1.3450664281845093 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,-1.3836947083473206 l10.214484930038452,5.177204608917236 0.0,-3.777959942817688 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l0.0,-3.777959942817688 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"},"metadata":{}},{"output_type":"stream","text":["Episode: 11, reward = 0.909618846694796\n","Episode: 12, reward = 0.909618846694796\n","Episode: 13, reward = 0.909618846694796\n","Episode: 14, reward = 0.909618846694796\n","Episode: 15, reward = 0.909618846694796\n","Episode: 16, reward = 0.9087661744022504\n","Episode: 17, reward = 0.8968653305203937\n","Episode: 18, reward = 0.8965066807313643\n","Episode: 19, reward = 0.895426511954993\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: actor_model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: actor_model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: critic_model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: critic_model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: target_actor_model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: target_actor_model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: target_critic_model/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: target_critic_model/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Saved all models to directory: /content/drive/My Drive/vinci-old/model/Pixel Maximizer\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ifAn79cr_tNR","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1629690708301,"user_tz":-330,"elapsed":43,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}},"outputId":"79cc0948-fa02-49dc-dad2-ef62b9aa51e9"},"source":["#Plot reward\n","plot_reward(history)"],"id":"ifAn79cr_tNR","execution_count":24,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":["Plot saved to ./results/Pixel Maximizer/final_reward.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GvwYX9fU_oIc","executionInfo":{"status":"ok","timestamp":1629690777530,"user_tz":-330,"elapsed":10369,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":["#Evaluate target actor\n","strokes = get_ground_truth()"],"id":"GvwYX9fU_oIc","execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_pNp2ORUW8H","colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"status":"ok","timestamp":1629690777536,"user_tz":-330,"elapsed":42,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}},"outputId":"756033df-69f1-4167-932b-e00ab28c0abe"},"source":["#Draw the evaluation results\n","draw.draw_strokes(strokes, svg_filename='./results/' + Model_Name + '/final.svg', save_to_file=True, show=True)"],"id":"Q_pNp2ORUW8H","execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.SVG object>"],"image/svg+xml":"<svg baseProfile=\"full\" height=\"294.20971542596817\" version=\"1.1\" width=\"1756.270998865366\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"294.20971542596817\" width=\"1756.270998865366\" x=\"0\" y=\"0\"/><path d=\"M25,106.33357047569007 m0.0,-1.4428678154945374 l10.214484930038452,-3.777959942817688 1.5104298293590546,-3.777959942817688 l2.818080186843872,-3.777959942817688 7.285877466201782,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.2416358590126038 l10.214484930038452,-2.013370096683502 10.214484930038452,-1.1282549798488617 l10.214484930038452,0.2661220543086529 7.908172607421875,3.0770158767700195 l9.166529178619385,5.177204608917236 10.214484930038452,5.177204608917236 l10.008742809295654,5.177204608917236 10.214484930038452,5.177204608917236 l9.24463152885437,4.616911709308624 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,5.177204608917236 l10.214484930038452,5.177204608917236 10.214484930038452,1.8292245268821716 l10.214484930038452,5.177204608917236 4.594773054122925,-0.3396189585328102 l10.214484930038452,4.251006543636322 4.517306089401245,-0.660223662853241 l10.214484930038452,3.4703803062438965 3.1674957275390625,-1.1948107928037643 l10.214484930038452,1.73314169049263 2.431199848651886,-1.5400820970535278 l9.509883522987366,0.5200545489788055 10.214484930038452,5.177204608917236 l1.2672162055969238,-0.359136164188385 10.214484930038452,0.2416183054447174 l10.214484930038452,4.4611164927482605 4.585852026939392,-0.3760133683681488 l10.214484930038452,4.164122045040131 1.696191430091858,-0.634726881980896 l10.214484930038452,-0.12521974742412567 10.214484930038452,3.6710333824157715 l2.561134397983551,-0.6655235588550568 10.214484930038452,3.4676480293273926 l5.621151328086853,-0.7974772155284882 10.214484930038452,-0.5370458215475082 l10.214484930038452,4.730153679847717 3.1386160850524902,-0.06242130417376757 l10.214484930038452,4.74524587392807 3.3401504158973694,-0.17837835475802422 l10.214484930038452,4.402296841144562 1.7936095595359802,-0.5679025873541832 l10.214484930038452,0.3947799652814865 10.214484930038452,4.439613521099091 l1.6749098896980286,-0.6314881145954132 10.214484930038452,-3.5864323377609253 l10.214484930038452,0.7175403088331223 4.640669524669647,-1.2476605921983719 l10.214484930038452,3.446080982685089 5.213109254837036,-0.21178796887397766 l2.098727822303772,-1.389612853527069 9.446893334388733,1.6743865609169006 l2.405215948820114,-1.1927126348018646 10.04598617553711,2.926192283630371 l2.277558743953705,-0.7096347957849503 10.214484930038452,3.2998445630073547 l2.3330509662628174,-0.6115688756108284 10.214484930038452,3.30284982919693 l4.297850728034973,-0.6078812852501869 10.214484930038452,4.118298590183258 l1.7680607736110687,-0.5562258139252663 10.214484930038452,-0.3815716505050659 l10.214484930038452,4.260475933551788 2.2139598429203033,-0.48307694494724274 l10.214484930038452,4.0177121758461 4.51239675283432,-0.4963725432753563 l10.214484930038452,4.352138042449951 3.455149829387665,-0.5011168122291565 l10.214484930038452,4.055381417274475 0.665728747844696,-0.6421549618244171 l10.214484930038452,-0.2711717039346695 10.214484930038452,4.138550162315369 l4.498341381549835,-0.7122785598039627 10.214484930038452,4.035077393054962 l2.6164934039115906,-0.5444687604904175 10.214484930038452,4.069008231163025 l2.939160466194153,-0.697101429104805 10.214484930038452,3.909592628479004 l4.730497598648071,-0.5072062462568283 10.214484930038452,-0.8469203859567642 l10.214484930038452,4.33393657207489 3.7944993376731873,-0.1620778813958168 l10.214484930038452,5.177204608917236 3.8504397869110107,-0.060878926888108253 l2.540496587753296,-2.1080929040908813 8.907663822174072,-1.1353488266468048 l10.214484930038452,2.3221921920776367 3.748619854450226,-0.8146112412214279 l10.214484930038452,4.0059152245521545 0.4923182725906372,-0.0718182884156704 l10.214484930038452,2.9671385884284973 5.154491066932678,-0.7398771494626999 l10.214484930038452,-0.7492674887180328 10.214484930038452,4.569687843322754 l4.8363566398620605,-0.008502928540110588 4.14472222328186,-1.4792229235172272 l10.214484930038452,-2.339983284473419 10.214484930038452,-2.352016419172287 l10.214484930038452,-2.251746654510498 10.214484930038452,-1.9902822375297546 l10.214484930038452,-1.9542711973190308 10.214484930038452,-1.69073686003685 l10.214484930038452,-1.688738763332367 10.214484930038452,-1.8186381459236145 l10.214484930038452,-1.7605245113372803 10.214484930038452,-1.5566244721412659 l10.214484930038452,-1.4039483666419983 10.214484930038452,-0.8011707663536072 l10.029196739196777,2.5582069158554077 9.61715281009674,4.485592842102051 l2.1186229586601257,1.5520195662975311 9.812041521072388,5.177204608917236 l3.1564873456954956,0.8767828345298767 10.214484930038452,5.177204608917236 l1.9842025637626648,0.42717453092336655 10.214484930038452,5.177204608917236 l2.6520681381225586,0.0831954088062048 10.214484930038452,4.866930246353149 l0.7594697177410126,-0.6273399293422699 10.214484930038452,-2.4007482826709747 l10.214484930038452,-3.1322482228279114 10.214484930038452,-2.9734331369400024 l10.214484930038452,-2.563284933567047 10.214484930038452,-2.991010546684265 l10.214484930038452,-3.676849603652954 10.214484930038452,-3.2053425908088684 l10.214484930038452,-3.042494058609009 10.214484930038452,-3.4515830874443054 l10.214484930038452,-3.5096123814582825 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.7737813591957092 l10.214484930038452,-3.40839684009552 10.214484930038452,-3.582065999507904 l10.214484930038452,-3.382605016231537 10.214484930038452,-3.651588559150696 l10.214484930038452,-3.684535324573517 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.6337313055992126 l10.214484930038452,-3.544357419013977 10.214484930038452,-3.6127400398254395 l10.214484930038452,-3.6589565873146057 10.214484930038452,-3.279324769973755 l10.214484930038452,-3.019484281539917 10.214484930038452,-2.943830192089081 l10.214484930038452,-3.1508085131645203 10.214484930038452,-3.1848007440567017 l10.214484930038452,-2.9773762822151184 10.214484930038452,-3.461066782474518 l10.214484930038452,-3.6894771456718445 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.6564037203788757 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 10.214484930038452,-3.777959942817688 l10.214484930038452,-3.777959942817688 \" fill=\"none\" stroke=\"black\" stroke-width=\"1\"/></svg>"},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ZINHnPeElUMz","executionInfo":{"status":"ok","timestamp":1629690147915,"user_tz":-330,"elapsed":20,"user":{"displayName":"Omkar Joglekar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_xqk9lidtgCA4fQFtWChbx946TCEiyAo1gmjF=s64","userId":"11401791877254082421"}}},"source":[""],"id":"ZINHnPeElUMz","execution_count":22,"outputs":[]}]}